{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "from image_processor.toolkit import *\n",
    "fname = 'parking01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(fname)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_traffic_sign_detector.config as config\n",
    "from train_traffic_sign_detector.tensorflow_object_detection.model_utils import load_model,visualize_detections_on_image,run_inference_for_single_image\n",
    "# from train_traffic_sign_detector.tensorflow_object_detection.model_utils import create_candidate_boxes_in_frame\n",
    "\n",
    "sess = load_model(config.MODEL_PATH)\n",
    "detections = run_inference_for_single_image(sess,im)\n",
    "visualized_image = visualize_detections_on_image(sess,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_boxes=create_candidate_boxes_in_frame(detections, visualized_image.shape, config.SCORE_THRESHOLD)\n",
    "box_images = []\n",
    "for box in candidate_boxes:\n",
    "    box_images.append(im[box['ymin']:box['ymax'],box['xmin']:box['xmax']])\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_images = []\n",
    "box_images.append(cv2.cvtColor(cv2.imread('park_box01.jpg'), cv2.COLOR_BGR2RGB))\n",
    "box_images.append(cv2.cvtColor(cv2.imread('park_box02.jpg'), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,box_image in enumerate(box_images):\n",
    "    h, w, c = box_image.shape\n",
    "    lines = get_hough_lines_from_image(box_image)\n",
    "    if (lines is None):\n",
    "        continue\n",
    "    save_hough_lines_image(np.copy(box_image),lines,'hough_lines_on_box_{}.jpg'.format(idx))\n",
    "    segmented = segment_by_angle_kmeans(lines)\n",
    "    intersections = segmented_intersections(segmented)\n",
    "    save_intersection_lines_image(np.copy(box_image),intersections,'intersection_hough_lines_on_box_{}.jpg'.format(idx))\n",
    "    \n",
    "    default_criteria_type = cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER\n",
    "    criteria = (default_criteria_type, 10, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    attempts = 10\n",
    "    pts = np.array(intersections).astype(np.float32)\n",
    "    # run kmeans on the coords\n",
    "    _, centers = cv2.kmeans(pts, 4, None, criteria, attempts, flags)[1:]\n",
    "    center_points = []\n",
    "    for center in centers:\n",
    "        x, y = center\n",
    "        x = max(x, 0)\n",
    "        y = max(y, 0)\n",
    "        center_points.append([x, y])\n",
    "\n",
    "    center_points = np.float32(center_points)\n",
    "    save_kmeans_coords_on_image(np.copy(box_image),center_points,'kmeans_on_box_{}.jpg'.format(idx))\n",
    "\n",
    "    \n",
    "    frame_extrema_points = np.float32([[0, 0], [0, h], [w, 0], [w, h]])\n",
    "    dist_matrix = cdist(center_points, frame_extrema_points)\n",
    "\n",
    "    points_matched = np.array([frame_extrema_points[np.argmin(i)] for i in dist_matrix])\n",
    "    M = cv2.getPerspectiveTransform(center_points, points_matched)\n",
    "\n",
    "    gray = cv2.cvtColor(box_image, cv2.COLOR_RGB2GRAY)\n",
    "    threshold_value, otsu_th_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    dst = cv2.warpPerspective(box_image, M, (w, h))\n",
    "    save_perspective_transformed_on_image(dst,'perspective_wrapped_on_box_{}.jpg'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = get_valid_perspective_from_localized_sign(box_images[0])\n",
    "imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "\n",
    "d = pytesseract.image_to_data(dst, lang='fra',output_type=Output.DICT)\n",
    "n_boxes = len(d['level'])\n",
    "for i in range(n_boxes):\n",
    "    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "    cv2.rectangle(dst, (x, y), (x + w, y + h), 0, 2)\n",
    "\n",
    "imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (d['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anaconda3)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
